---
title: "Scrape_Abgeordnete_2"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(stringr)
library(rvest)
politicians <- read.csv("C:\\Users\\shado\\Documents\\Abgeordnete_Kommunikation\\politicians_v2.1.csv", header = TRUE, stringsAsFactors = FALSE, sep = ";")
```

## Profile pages

This script will scrape the profile pages of the Abgeordneten for information about their Abgeordnetenwatch-ID, the number of asked questions, the number of answered questions

```{r}
profile_urls <- politicians$Profile

data <- data.frame(ID = numeric(), No_of_answers = numeric(), No_of_questions = numeric())

for (i in 1:length(profile_urls)) {  
  
  html <- read_html(profile_urls[i])
  
  # extract stats to questions
  question_stats <- html_elements(html, "div > span.stats__digit") %>%
    html_text() %>%
    str_split("/")

  # convert text to numeric
  questions_answered <- question_stats[[1]][2] %>%
    substr(2, nchar(.)) %>%
    as.numeric()

  # convert text to numeric
  questions_asked <- question_stats[[1]][1] %>%
    substr(1, nchar(.)-1) %>%
    as.numeric()

  # extract politician ID 
  id <- html_element(html, "div.api-link > a") %>%
    html_attr("href") %>%
    str_split("/open-data/info/politician/") 
  id <- as.numeric(id[[1]][2])
  
  # add data to dataframe
  data <- rbind(data, list(id, questions_answered, questions_asked))
}
```

```{r}
# combine dataframes + export as csv
politicians_1 <- cbind(politicians, data)

# correctly name the columns
names(politicians_1) <- c("Name", "Party", "Parliament", "Q_A_Link", "ID", "Q_asked", "Q_answered")

# remove double entries from dataframe
politicians_2 <- unique(politicians_1)

# export dataframe
write.csv(politicians_2, "C:\\Users\\shado\\Documents\\Abgeordnete_Kommunikation\\politicians_v3.csv", row.names = FALSE)
```
