---
title: "Scrape_Abgeordnete_2"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(stringr)
library(rvest)
politicians <- read.csv("C:\\Users\\shado\\Documents\\Abgeordnete_Kommunikation\\politicians_v2.csv", header = TRUE, stringsAsFactors = FALSE)
```

## Profile pages

This script will scrape the profile pages of the Abgeordneten for information about their ID, the qustions asked, answered questions, the tags of the question, the number of asked questions, the number of answered questions

```{r}
profile_urls <- politicians$Profile

data <- data.frame(ID = numeric(), No_of_answers = numeric(), No_of_questions = numeric())

for (i in 1:length(profile_urls)) {  
  
  html <- read_html(profile_urls[i])
  
  # extract stats to questions
  question_stats <- html_elements(html, "div > span.stats__digit") %>%
    html_text() %>%
    str_split("/")
  
  # convert text to numeric
  questions_answered <- question_stats[[1]][2] %>%
    substr(2, nchar(.)) %>%
    as.numeric()

  # convert text to numeric
  questions_asked <- question_stats[[1]][1] %>%
    substr(1, nchar(.)-1) %>%
    as.numeric()

  # extract politician ID 
  id <- html_element(html, "div.api-link > a") %>%
    html_attr("href") %>%
    str_split("/open-data/info/politician/") 
  id <- as.numeric(id[[1]][2])
  
  # add data to dataframe
  data <- rbind(data, list(id, questions_answered, questions_asked))
}

```

```{r}
# combine dataframes + export as csv
politicians <- list(politicians, data) %>%
  reduce(full_join, by="variable_name")

write_csv(politicians, "C:\\shado\\Documents\\Abgeordnete_Kommunikation\\politicians_v3.csv")
```
